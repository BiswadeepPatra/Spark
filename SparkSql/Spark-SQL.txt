There are different types of data sources available in SparkSQL, some of which are listed below:
	JSON Datasets
	Hive Tables
	Parquet Files

https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.2/bk_spark-guide/content/ch_spark-hive-access.html

http://www.infoobjects.com/sparksql-sqlcontext-vs-hivecontext/

val sqlcontext = new org.apache.spark.sql.SQLContext(sc)

employee.json

{{"id" : 1201, "name" : "satish", "age" : 25}
{"id" : 1202, "name" : "krishna", "age" : 28}
{"id" : 1203, "name" : "amith", "age" : 39}
{"id" : 1204, "name" : "javed", "age" : 23}
{"id" : 1205, "name" : "prudvi", "age" : 23}}

case class Movies ( id:String, title:String, year:String,genre:String,Summary:String,country:String, )

case class director ( id:String, last_name:String, first_name:String,year_of_birth:String )

case class actors ( id:String, title:String, year:String,genre:String,Summary:String,country:String, )

val dfs = sqlContext.read.json("employee.json")

dfs.show()

dfs.printSchema()

dfs.select("name").show()

dfs.filter(dfs("age") > 23).show()

dfs.groupBy("age").count().show()



employee.txt

1201,Satish,25
1202,Krishna,28
1203,Amith,39
1204,Javed,23
1205,Prudvi,23

val sqlContext = new org.apache.spark.sql.SQLContext(sc)

import sqlContext.implicts._

case class Employee(id: Int, name: String, age: Int)

val empl=sc.textFile("employee.txt").map(_.split(",")).map(e=>employee(e(0).trim.toInt,e(1), e(2).trim.toInt)).toDF()

empl.registerTempTable("employee")

val allrecords = sqlContext.sql("SELECT * FROM employee")

allrecords.show()

val agefilter = sqlContext.sql("SELECT * FROM employee WHERE age>=20 AND age <= 35")

agefilter.show()



employee.txt

1201,Satish,25
1202,Krishna,28
1203,Amith,39
1204,Javed,23
1205,Prudvi,23

val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)

hiveContext.sql("CREATE TABLE employee(id INT, name STRING, age INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','")

hiveContext.sql("LOAD DATA LOCAL INPATH '/home/cloudera/employee.txt' INTO TABLE employee")

val result = hiveContext.sql("FROM employee SELECT id, name, age")

val result = hiveContext.sql( "select * from artist ")

result.show()



val sqlContext = new org.apache.spark.sql.SQLContext(sc)

val parqfile = sqlContext.read.parquet("file:///home/cloudera/order_items.parquet")

parqfile.registerTempTable("order_items")

val allrecords = sqlContext.sql("select * FROM order_items limit 3")

allrecords.show()



